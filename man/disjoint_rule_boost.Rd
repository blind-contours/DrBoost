% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DrBoost.R
\name{disjoint_rule_boost}
\alias{disjoint_rule_boost}
\title{Disjoint Rule Boosting (Gradient-Boosting Style) with Excluding Repeated Failing Regions}
\usage{
disjoint_rule_boost(
  X_train,
  Y_train,
  X_val,
  Y_val,
  outcome_type = c("continuous", "binary"),
  thresholds_list = NULL,
  logic = FALSE,
  K1 = 200,
  K2 = 200,
  K3 = 200,
  K4 = 200,
  featureNames = character(0),
  K_twoWay = 100,
  K_threeWay = 100,
  max_iterations = 20,
  learning_rate = 0.1,
  min_obs_pct = 0.05,
  max_obs_frac = 1,
  patience = 3,
  second_order_logistic = TRUE,
  max_region_retries = 5
)
}
\arguments{
\item{X_train}{matrix or data.frame of shape (n x p)}

\item{Y_train}{numeric vector (length n): continuous or {0,1}}

\item{X_val}{matrix or data.frame of shape (m x p)}

\item{Y_val}{numeric vector (length m)}

\item{outcome_type}{"continuous" or "binary"}

\item{thresholds_list}{numeric matrix for bounding-box approach (if logic=FALSE)}

\item{logic}{boolean; if TRUE, do logic-based search. If FALSE, bounding-box}

\item{K1, K2, K3, K4}{integers for beam-search expansions (bounding-box)}

\item{featureNames}{character vector of length p (for bounding-box rule strings)}

\item{K_twoWay, K_threeWay}{integers for logic expansions}

\item{max_iterations}{integer, maximum boosting steps}

\item{learning_rate}{numeric, e.g. 0.1}

\item{min_obs_pct}{numeric, min coverage fraction}

\item{max_obs_frac}{numeric, max coverage fraction to avoid giant rules}

\item{patience}{integer, early-stopping if no improvement for \code{patience} steps}

\item{second_order_logistic}{bool: if TRUE, uses 2nd-order updates for logistic}

\item{max_region_retries}{integer, how many candidate boxes we try per iteration
before concluding none helps validation}
}
\value{
A list with:
\item{init}{the initial intercept (numeric scalar)}
\item{rule_list}{list of discovered rules (each with coverage, beta, region info)}
\item{f_train}{final fitted values on training (numeric vector)}
\item{f_val}{final fitted values on validation}
\item{train_loss_final}{final train loss}
\item{val_loss_final}{final validation loss}
\item{validation_losses}{history of validation losses}
\item{best_val_loss}{lowest validation loss found}
\item{best_iteration}{iteration index with best validation}
}
\description{
Builds a piecewise-constant model as a sum of disjoint rules,
with gradient-boosting style updates and a small loop each iteration
to skip repeated failing regions. If the top region from beam-search
hurts validation loss, we exclude that region (so it won't keep appearing)
and re-run beam-search to get the next-best box, up to \code{max_region_retries} tries.
}
